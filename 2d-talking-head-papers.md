# 2025

OmniHuman-1: Rethinking the Scaling-Up of One-Stage Conditioned Human Animation Models; [arXiv 2025](https://arxiv.org/abs/2502.01061); [Project](https://omnihuman-lab.github.io/); [CSDN](https://blog.csdn.net/A_D_I_D_A_S/article/details/145502287); 

SyncAnimation: A Real-Time End-to-End Framework for Audio-Driven Human Pose and Talking Head Animation; [arXiv 2025](https://arxiv.org/pdf/2501.14646); [Project](https://syncanimation.github.io/); [CSDN](https://blog.csdn.net/A_D_I_D_A_S/article/details/145406554); 

EMO2: End-Effector Guided Audio-Driven Avatar Video Generation; [arXiv 2025](https://arxiv.org/pdf/2501.10687); [Project](https://humanaigc.github.io/emote-portrait-alive-2/); [CSDN](https://blog.csdn.net/A_D_I_D_A_S/article/details/145331492); 

Joint Learning of Depth and Appearance for Portrait Image Animation; [arXiv 2025](https://arxiv.org/abs/2501.08649); [CSDN](https://blog.csdn.net/A_D_I_D_A_S/article/details/145331590); 

UniAvatar: Taming Lifelike Audio-Driven Talking Head Generation with Comprehensive Motion and Lighting Control;  [arXiv 2025](https://www.arxiv.org/abs/2412.19860); [CSDN](https://blog.csdn.net/A_D_I_D_A_S/article/details/145077676); 

MoEE: Mixture of Emotion Experts for Audio-Driven Portrait Animation;  [arXiv 2025](https://arxiv.org/abs/2501.01808); [CSDN](https://blog.csdn.net/A_D_I_D_A_S/article/details/145044690); 

VividTalk: One-Shot Audio-Driven Talking Head Generation Based on 3D Hybrid Prior; [3DV 2025](https://arxiv.org/abs/2312.01841); [Project](https://humanaigc.github.io/vivid-talk/); [Code](https://github.com/HumanAIGC/VividTalk); [CSDN](https://blog.csdn.net/A_D_I_D_A_S/article/details/145560934); 

INFP: Audio-Driven Interactive Head Generation in Dyadic Conversations; [arXiv 2025](https://arxiv.org/abs/2412.04037); [Project](https://grisoon.github.io/INFP/); [CSDN](https://blog.csdn.net/A_D_I_D_A_S/article/details/144383953); 

# 2024

LetsTalk: Latent Diffusion Transformer for Talking Video Synthesis; [arXiv 2024](https://arxiv.org/abs/2411.16748); [Project](https://zhang-haojie.github.io/project-pages/letstalk.html); [Code](https://github.com/zhang-haojie/letstalk); [CSDN](https://blog.csdn.net/A_D_I_D_A_S/article/details/144567850); 

Sonic: Shifting Focus to Global Audio Perception in Portrait Animation; [arXiv 2024](https://arxiv.org/abs/2411.16331); [Project](https://jixiaozhong.github.io/Sonic/); [Code](https://github.com/jixiaozhong/Sonic); [CSDN](https://blog.csdn.net/A_D_I_D_A_S/article/details/144461131); 

IF-MDM: Implicit Face Motion Diffusion Model for High-Fidelity Realtime Talking Head Generation; [arXiv 2024](https://arxiv.org/abs/2412.04000); [Project](http://ec2-3-25-102-128.ap-southeast-2.compute.amazonaws.com/IF-MDM/ifmdm_supplementary/index.html); [CSDN](https://blog.csdn.net/A_D_I_D_A_S/article/details/144437117); 

PersonaTalk: Bring Attention to Your Persona in Visual Dubbing; [SIGGRAPH Asia 2024](https://arxiv.org/abs/2409.05379); [Project](https://grisoon.github.io/PersonaTalk/); [CSDN](https://blog.csdn.net/A_D_I_D_A_S/article/details/143242962); 

TALK-Act: Enhance Textural-Awareness for 2D Speaking Avatar Reenactment with Diffusion Model; [SIGGRAPH Asia 2024](https://arxiv.org/abs/2410.10696); [Project](https://guanjz20.github.io/projects/TALK-Act/); [CSDN](https://blog.csdn.net/A_D_I_D_A_S/article/details/143261671); 

Hallo: Hierarchical Audio-Driven Visual Synthesis for Portrait Image Animation; [arXiv 2024](https://arxiv.org/abs/2406.08801); [Project](https://fudan-generative-vision.github.io/hallo/#/); [Code](https://github.com/fudan-generative-vision/hallo); [CSDN](https://blog.csdn.net/A_D_I_D_A_S/article/details/143418507); 

EMO: Emote Portrait Alive -- Generating Expressive Portrait Videos with Audio2Video Diffusion Model under Weak Conditions; [arXiv 2024](https://arxiv.org/abs/2402.17485); [Project](https://humanaigc.github.io/emote-portrait-alive/); [Code](https://github.com/HumanAIGC/EMO); 

MEMO: Memory-Guided Diffusion for Expressive Talking Video Generation; [arXiv 2024](https://arxiv.org/abs/2412.04448); [Project](https://memoavatar.github.io/); [Code](https://github.com/memoavatar/memo); [CSDN](https://blog.csdn.net/A_D_I_D_A_S/article/details/144384770); 

# 2023

DiffTalk: Crafting Diffusion Models for Generalized Audio-Driven Portraits Animation; [CVPR 2023](https://arxiv.org/abs/2301.03786); [Project](https://sstzal.github.io/DiffTalk/); [Code](https://github.com/sstzal/DiffTalk); 

SadTalker: Learning Realistic 3D Motion Coefficients for Stylized Audio-Driven Single Image Talking Face Animation; [CVPR 2023](https://arxiv.org/abs/2211.12194); [Code](https://github.com/Winfredy/SadTalker); [Project](https://sadtalker.github.io/); [CSDN](https://mp.csdn.net/mp_blog/creation/success/145406735); 

# 2022

EAMM: One-Shot Emotional Talking Face via Audio-Based Emotion-Aware Motion Model; [SIGGRAPH 2022](https://arxiv.org/abs/2205.15278); [Code](https://github.com/jixinya/EAMM); [Project](https://jixinya.github.io/projects/EAMM/); [CSDN](https://blog.csdn.net/A_D_I_D_A_S/article/details/145559700); 

Implicit Warping for Animation with Image Sets; [NeurIPS 2022](https://arxiv.org/abs/2210.01794); [CSDN](https://blog.csdn.net/A_D_I_D_A_S/article/details/143261310); 

# 2021

Audio-Driven Emotional Video Portraits; [CVPR 2021](https://arxiv.org/abs/2104.07452); [Code](https://github.com/jixinya/EVP/); [Project](https://jixinya.github.io/projects/evp/); [CSDN](https://blog.csdn.net/A_D_I_D_A_S/article/details/145559729); 

Live Speech Portraits: Real-Time Photorealistic Talking-Head Animation; [ACM TOG 2021](https://arxiv.org/abs/2109.10595); [Code](https://github.com/YuanxunLu/LiveSpeechPortraits); [CSDN](https://blog.csdn.net/A_D_I_D_A_S/article/details/145560915); 

# 2020

A Lip Sync Expert Is All You Need for Speech to Lip Generation In The Wild; [ACMMM 2020](https://arxiv.org/abs/2008.10010); [Code](https://github.com/Rudrabha/Wav2Lip); [Project](http://cvit.iiit.ac.in/research/projects/cvit-projects/a-lip-sync-expert-is-all-you-need-for-speech-to-lip-generation-in-the-wild/); [CSDN](https://mp.csdn.net/mp_blog/creation/success/145406697); 